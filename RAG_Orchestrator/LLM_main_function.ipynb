{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBi4XNKKyESx",
        "outputId": "3f869c35-4f3a-4336-e87d-e55c57ab5159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in c:\\program files\\python311\\lib\\site-packages (0.4.8)\n",
            "Requirement already satisfied: langsmith in c:\\program files\\python311\\lib\\site-packages (0.3.45)\n",
            "Requirement already satisfied: langchain in c:\\program files\\python311\\lib\\site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain_community in c:\\program files\\python311\\lib\\site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core>=0.1 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith) (1.26.15)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\program files\\python311\\lib\\site-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\program files\\python311\\lib\\site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\program files\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (3.12.12)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\program files\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\program files\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu in c:\\program files\\python311\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\program files\\python311\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python311\\lib\\site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: sentence-transformers in c:\\program files\\python311\\lib\\site-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (2.7.0+cu128)\n",
            "Requirement already satisfied: scikit-learn in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: langchain-huggingface in c:\\program files\\python311\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.3.65)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.33.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.13.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.26.15)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.30.2->langchain-huggingface) (0.4.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\program files\\python311\\lib\\site-packages (2.1.5)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (0.3.65)\n",
            "Requirement already satisfied: pydantic<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (2.11.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.17.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\program files\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.15)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\program files\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: langchain_openai in c:\\program files\\python311\\lib\\site-packages (0.3.23)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (0.3.65)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (1.88.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.13.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.11.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.26.15)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\program files\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain_openai) (0.4.6)\n",
            "Downloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n",
            "Installing collected packages: langchain_openai\n",
            "  Attempting uninstall: langchain_openai\n",
            "    Found existing installation: langchain-openai 0.3.23\n",
            "    Uninstalling langchain-openai-0.3.23:\n",
            "      Successfully uninstalled langchain-openai-0.3.23\n",
            "Successfully installed langchain_openai-0.3.24\n",
            "Requirement already satisfied: openai in c:\\program files\\python311\\lib\\site-packages (1.88.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in c:\\program files\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\program files\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: pinecone in c:\\program files\\python311\\lib\\site-packages (7.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (2022.12.7)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (4.13.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (1.26.15)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\program files\\python311\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\program files\\python311\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
            "Requirement already satisfied: flashrank in c:\\program files\\python311\\lib\\site-packages (0.2.10)\n",
            "Requirement already satisfied: tokenizers in c:\\program files\\python311\\lib\\site-packages (from flashrank) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime in c:\\program files\\python311\\lib\\site-packages (from flashrank) (1.22.0)\n",
            "Requirement already satisfied: numpy in c:\\program files\\python311\\lib\\site-packages (from flashrank) (1.26.4)\n",
            "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from flashrank) (2.32.4)\n",
            "Requirement already satisfied: tqdm in c:\\program files\\python311\\lib\\site-packages (from flashrank) (4.67.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (23.3.3)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (24.2)\n",
            "Requirement already satisfied: protobuf in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (6.31.1)\n",
            "Requirement already satisfied: sympy in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\program files\\python311\\lib\\site-packages (from coloredlogs->onnxruntime->flashrank) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\program files\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->flashrank) (3.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (2022.12.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy->onnxruntime->flashrank) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\program files\\python311\\lib\\site-packages (from tokenizers->flashrank) (0.33.0)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (4.13.0)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm->flashrank) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "!pip install langgraph langsmith langchain langchain_community\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers\n",
        "!pip install -U langchain-huggingface\n",
        "!pip install -U langchain-google-genai\n",
        "!pip install -U langchain_openai\n",
        "!pip install -U openai\n",
        "!pip install -U pinecone\n",
        "!pip install flashrank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9JnlZTf-btn"
      },
      "source": [
        "## PINECONE DB RETRIEVER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yMo-66Ei-bto"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pinecone import Pinecone\n",
        "from typing import List, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain.schema import BaseRetriever, Document\n",
        "from langchain.load import dumps, loads\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "class PineconeDBRetriever(BaseRetriever, BaseModel):\n",
        "    \"\"\"\n",
        "    A custom LangChain retriever for Pinecone.\n",
        "    \"\"\"\n",
        "    index_name: str\n",
        "    pinecone_api_key: str\n",
        "    namespace: str\n",
        "    top_k: int = 5\n",
        "    index: Any = Field(None, exclude=True)\n",
        "\n",
        "    def __init__(self, **data):\n",
        "        \"\"\"\n",
        "        Initializes the Pinecone client and index.\n",
        "        \"\"\"\n",
        "        super().__init__(**data)\n",
        "        pc = Pinecone(api_key=self.pinecone_api_key)\n",
        "        self.index = pc.Index(self.index_name)\n",
        "\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        The core method to retrieve documents. LangChain's retriever system\n",
        "        calls this method.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's question.\n",
        "\n",
        "        Returns:\n",
        "            List[Document]: A list of relevant documents from Pinecone.\n",
        "        \"\"\"\n",
        "        # Pinecone's hosted embedding model will automatically embed the query text.\n",
        "        results = self.index.search(\n",
        "            namespace=self.namespace,\n",
        "            query={\n",
        "                \"inputs\": {\"text\": query},\n",
        "                \"top_k\": self.top_k\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Convert Pinecone's search results into LangChain Document objects.\n",
        "        # TODO: Add additional fields as necessary.\n",
        "        documents = []\n",
        "        if results and 'result' in results and 'hits' in results['result']:\n",
        "            for match in results['result']['hits']:\n",
        "                # The actual text content is in the 'fields' dictionary\n",
        "                page_content = match.get('fields', {}).get('text', '')\n",
        "                # metadata = {\"id\": match.get(\"_id\"), \"score\": match.get(\"_score\")}\n",
        "                metadata = {\"id\": match.get(\"_id\")} # Removing score to allow easy serialization and help de-duplication\n",
        "\n",
        "                doc = Document(\n",
        "                    page_content=page_content,\n",
        "                    metadata=metadata\n",
        "                )\n",
        "                documents.append(doc)\n",
        "\n",
        "        return documents\n",
        "\n",
        "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Asynchronous version of the document retrieval method.\n",
        "        \"\"\"\n",
        "        # For simplicity, we'll just call the synchronous version.\n",
        "        # For a production environment, you might want to use an async Pinecone client.\n",
        "        return self._get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33r0fv9-btp"
      },
      "source": [
        "## RAG ORCHESTRATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DpJuH5l9-btp"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableConfig, RunnableParallel\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pprint import pprint\n",
        "from typing import Any, List\n",
        "from langchain.load import dumps, loads\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "class RAGOrchestrator:\n",
        "    \"\"\"\n",
        "    Orchestrates the RAG pipeline based on a given configuration.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: dict):\n",
        "        \"\"\"\n",
        "        Initializes the orchestrator with a configuration dictionary.\n",
        "\n",
        "        Args:\n",
        "            config (dict): A dictionary containing settings for the RAG pipeline,\n",
        "                           such as model name, index name, and retrieval strategy.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.debug = config.get(\"debug\", False)\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=config.get(\"llm_model\", \"gpt-4o-mini\"),\n",
        "            api_key=OPENAI_API_KEY\n",
        "        )\n",
        "        if config.get(\"retrieval_strategy\") != \"llm_only\":\n",
        "            self.retriever = PineconeDBRetriever(\n",
        "                index_name=config.get(\"index_name\"),\n",
        "                pinecone_api_key=PINECONE_API_KEY,\n",
        "                namespace=config.get(\"namespace\"),\n",
        "                top_k=config.get(\"top_k\", 5)\n",
        "            )\n",
        "\n",
        "    # --- Debugging Helper ---\n",
        "    def _print_debug(self, header: str, data: Any):\n",
        "        if self.debug:\n",
        "            print(\"\\n\" + \"=\"*20)\n",
        "            print(f\"DEBUG: {header}\")\n",
        "            print(\"=\"*20)\n",
        "            pprint(data)\n",
        "        return data # Pass data through unchanged\n",
        "\n",
        "    def _tap_and_log(self, x: dict) -> dict:\n",
        "        \"\"\"\n",
        "        A helper method to print debug info and pass the input dictionary through unchanged.\n",
        "        \"\"\"\n",
        "        self._print_debug(\"Final Context for LLM\", x.get(\"context_str\", \"Context not available\"))\n",
        "        return x\n",
        "\n",
        "    def _get_unique_union(self, documents: list[list]) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Takes a list of document lists, merges them, and removes duplicates.\n",
        "        \"\"\"\n",
        "        # Serialize each document to a string to make them hashable\n",
        "        flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "        # Use a set to get unique serialized documents\n",
        "        unique_docs = list(set(flattened_docs))\n",
        "        # Deserialize unique documents back into Document objects\n",
        "        return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "    # --- Retrieval Strategy Helpers ---\n",
        "\n",
        "    def _get_multi_query_chain(self):\n",
        "        # Builds a chain that generates multiple queries and retrieves documents for each.\n",
        "        # 1. Prompt for generating multiple queries\n",
        "        template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "        different versions of the given user question to retrieve relevant documents from a vector\n",
        "        database. By generating multiple perspectives on the user question, your goal is to help\n",
        "        the user overcome some of the limitations of the cosine-based similarity search.\n",
        "        Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "        prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        # 3. The chain for generating and retrieving\n",
        "        generate_queries = (\n",
        "            prompt_perspectives\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Queries\", x))\n",
        "        )\n",
        "\n",
        "        retrieval_chain = generate_queries | self.retriever.map() | self._get_unique_union | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_rag_fusion_chain(self):\n",
        "        \"\"\"Builds a chain for RAG Fusion with reciprocal rank fusion.\"\"\"\n",
        "        # 1. The multi-query generation is the same as above\n",
        "        template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "        different versions of the given user question to retrieve relevant documents from a vector\n",
        "        database. By generating multiple perspectives on the user question, your goal is to help\n",
        "        the user overcome some of the limitations of the cosine-based similarity search.\n",
        "        Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "        prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        generate_queries = (\n",
        "            prompt_perspectives\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Queries\", x))\n",
        "        )\n",
        "\n",
        "        # 2. Reranking with Reciprocal Rank Fusion\n",
        "        def reciprocal_rank_fusion(results: list[list], k=60):\n",
        "            fused_scores = {}\n",
        "            for docs in results:\n",
        "                for rank, doc in enumerate(docs):\n",
        "                    doc_str = dumps(doc)\n",
        "                    if doc_str not in fused_scores:\n",
        "                        fused_scores[doc_str] = 0\n",
        "                    fused_scores[doc_str] += 1 / (rank + k)\n",
        "\n",
        "            # .item() converts [doc_str: score] pairs to a list of tuples [doc_str, score]\n",
        "            # Sort by score in descending order (reverse=True)\n",
        "            reranked_results = [\n",
        "                (loads(doc), score)\n",
        "                for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            ]\n",
        "            self._print_debug(\"Reranked Documents (RAG Fusion)\", reranked_results)\n",
        "            # Return only the documents, not the scores\n",
        "            return [doc for doc, score in reranked_results]\n",
        "\n",
        "        # 3. The RAG Fusion chain\n",
        "        retrieval_chain = generate_queries | self.retriever.map() | reciprocal_rank_fusion\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_decomposition_chain(self):\n",
        "        # Builds a chain that decomposes a question into sub-questions.\n",
        "        # 1. Prompt for generating sub-questions\n",
        "        decomposition_template = \"\"\"You are a helpful assistant that generates multiple sub-questions\n",
        "        related to an input question. The goal is to break down the input into a set of sub-problems\n",
        "        that can be answered in isolation. Generate multiple search queries related to: {question}\n",
        "        Output (separated by newlines):\"\"\"\n",
        "        prompt_decomposition = ChatPromptTemplate.from_template(decomposition_template)\n",
        "\n",
        "        # 2. Chain to generate and clean up sub-questions\n",
        "        generate_queries_decomposition = (\n",
        "            prompt_decomposition\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Decomposed Sub-questions\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain using the decomposed questions\n",
        "        retrieval_chain = (\n",
        "            generate_queries_decomposition\n",
        "            | self.retriever.map()\n",
        "            | self._get_unique_union\n",
        "            | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (Decomposition)\", docs)\n",
        "            ))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_step_back_chain(self):\n",
        "        # Builds a chain that generates a general, \"stepped-back\" question and retrieves documents for it.\n",
        "        # 1. Prompt to generate a more general, \"stepped-back\" question\n",
        "        step_back_template = \"\"\"You are an expert at world knowledge. Your task is to step back and\n",
        "        paraphrase a question to a more generic step-back question, which is easier to answer.\n",
        "\n",
        "        Here are a few examples:\n",
        "        Original Question: What is the C29x CPU architecture in the F29H85x microcontroller?\n",
        "        Step-Back Question: What are the technical specifications of the C29x CPU architecture?\n",
        "\n",
        "        Original Question: Which TI device was recommended for automotive radar in the 2023 safety seminar?\n",
        "        Step-Back Question: What are some common TI devices used for automotive radar applications?\n",
        "\n",
        "        Original Question: {question}\n",
        "        Step-Back Question:\"\"\"\n",
        "        prompt_step_back = ChatPromptTemplate.from_template(step_back_template)\n",
        "\n",
        "        # 2. Chain to generate the new question\n",
        "        generate_step_back_query = (\n",
        "            prompt_step_back\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            #| (lambda x: x.split(\"\\n\"))\n",
        "            #| RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Step-Back Question\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain using the new question\n",
        "        # This takes the original question, generates a new one, and retrieves docs with it\n",
        "        retrieval_chain = generate_step_back_query | self.retriever | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (Step back)\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_hyde_chain(self):\n",
        "        # Builds a chain that generates a hypothetical document and uses it for retrieval.\n",
        "\n",
        "        # 1. Prompt to generate a hypothetical document (a plausible answer)\n",
        "        hyde_template = \"\"\"Please write a passage to answer the user's question.\n",
        "        This passage should be detailed and informative, as if it came from a technical document.\n",
        "        The purpose is to create a rich text for a vector search.\n",
        "\n",
        "        Question: {question}\n",
        "        Passage:\"\"\"\n",
        "        prompt_hyde = ChatPromptTemplate.from_template(hyde_template)\n",
        "\n",
        "        # 2. Chain to generate the hypothetical document\n",
        "        generate_hyde_document = (\n",
        "            prompt_hyde\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Hypothetical Document\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain: generate a hypothetical doc, then retrieve with it\n",
        "        retrieval_chain = generate_hyde_document | self.retriever | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (HyDE)\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_st_reranking_chain(self):\n",
        "        \"\"\"\n",
        "        Creates a Runnable that performs semantic re-ranking using a\n",
        "        Cross-Encoder model from the sentence-transformers library.\n",
        "        \"\"\"\n",
        "        # Initialize a cross-encoder model. This model is lightweight and effective.\n",
        "        # It will be downloaded from the Hugging Face Hub on first use.\n",
        "        model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "        def rerank_docs(inputs: dict):\n",
        "            documents = inputs.get(\"documents\", [])\n",
        "            query = inputs.get(\"query\", \"\")\n",
        "            if not documents or not query:\n",
        "                return []\n",
        "\n",
        "            self._print_debug(f\"Documents going INTO Re-ranker ({len(documents)} docs)\", documents)\n",
        "\n",
        "            # 1. Create pairs of [query, passage] for the cross-encoder\n",
        "            sentence_pairs = [(query, doc.page_content) for doc in documents]\n",
        "\n",
        "            # 2. Predict the relevance scores. The output is a list of scores.\n",
        "            scores = model.predict(sentence_pairs)\n",
        "\n",
        "            # 3. Combine the original documents with their new scores\n",
        "            scored_docs = list(zip(scores, documents))\n",
        "\n",
        "            # 4. Sort the documents by score in descending order\n",
        "            scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "            # 5. Extract the documents and limit by top_n\n",
        "            reranked_docs = [doc for score, doc in scored_docs]\n",
        "            configured_top_n = self.config.get(\"reranker_top_n\", 5)\n",
        "            effective_top_n = min(configured_top_n, len(reranked_docs))\n",
        "            final_docs_to_return = reranked_docs[:effective_top_n]\n",
        "            \n",
        "            self._print_debug(f\"Documents COMING OUT of Re-ranker ({len(final_docs_to_return)} docs)\", final_docs_to_return)\n",
        "            return final_docs_to_return\n",
        "\n",
        "        return RunnableLambda(rerank_docs)\n",
        "    \n",
        "    def _get_contextual_compression_retriever(self, base_retriever):\n",
        "        \"\"\"\n",
        "        Takes a base retriever and wraps it with a compressor.\n",
        "        \"\"\"\n",
        "        # 1. Initialize the compressor. This component uses an LLM to read each retrieved document and extract only the sentences relevant to the query.\n",
        "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
        "\n",
        "        # 2. Create the compression retriever. This is a wrapper that first runs the base_retriever, then passes the results to the compressor.\n",
        "        compression_retriever = ContextualCompressionRetriever(\n",
        "            base_compressor=compressor,\n",
        "            base_retriever=base_retriever\n",
        "        )\n",
        "        \n",
        "        self._print_debug(\"Contextual Compression Retriever\", \"Initialized and ready.\")\n",
        "        return compression_retriever    \n",
        "\n",
        "    def invoke(self, question: str) -> dict:\n",
        "        \"\"\"\n",
        "        Builds and invokes the RAG chain based on the configuration.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's question.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the question, retrieved context, and the final answer.\n",
        "        \"\"\"\n",
        "        strategy = self.config.get(\"retrieval_strategy\", \"simple\")\n",
        "        post_processing_strategy = self.config.get(\"post_retrieval_processing\", \"none\")\n",
        "\n",
        "        # LLM_only strategy does not use retrieval\n",
        "        if strategy == \"llm_only\":\n",
        "            self._print_debug(\"Strategy\", \"LLM Only (No RAG)\")\n",
        "            answer = self.llm.invoke(question).content\n",
        "            return {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"strategy\": strategy,\n",
        "                \"context\": \"N/A\" # No context was used\n",
        "            }\n",
        "\n",
        "        # --- For RAG-based strategies ---\n",
        "\n",
        "        # Select the base retrieval chain (gets the initial list of documents)\n",
        "        if strategy == \"multi_query\":\n",
        "            base_retrieval_chain = self._get_multi_query_chain()\n",
        "        elif strategy == \"rag_fusion\":\n",
        "            base_retrieval_chain = self._get_rag_fusion_chain()\n",
        "        elif strategy == \"decomposition\":\n",
        "            base_retrieval_chain = self._get_decomposition_chain()\n",
        "        elif strategy == \"step_back\":\n",
        "            base_retrieval_chain = self._get_step_back_chain()\n",
        "        elif strategy == \"hyde\":\n",
        "            base_retrieval_chain = self._get_hyde_chain()\n",
        "        # -----------------------------\n",
        "        else: # Default to simple retrieval\n",
        "            base_retrieval_chain = self.retriever | RunnableLambda(\n",
        "                lambda docs: self._print_debug(\"Retrieved Documents (Simple)\", docs)\n",
        "            )\n",
        "\n",
        "        # Conditionally apply post-processing\n",
        "        # If no post-processing is specified, use the base retrieval chain as is\n",
        "        final_retrieval_chain = base_retrieval_chain\n",
        "        \n",
        "        if \"semantic_re_ranking\" in post_processing_strategy:\n",
        "            # The re-ranker needs both docs and query\n",
        "            reranker_chain = {\"documents\": final_retrieval_chain, \"query\": RunnablePassthrough()} | self._get_st_reranking_chain()\n",
        "            final_retrieval_chain = reranker_chain\n",
        "        \n",
        "        # Step 2b: Conditionally apply the compression layer\n",
        "        if \"contextual_compression\" in post_processing_strategy:\n",
        "            # The compression retriever wraps the base retriever\n",
        "            final_retrieval_chain = self._get_contextual_compression_retriever(final_retrieval_chain)\n",
        "\n",
        "\n",
        "        final_prompt_template = \"\"\"Answer the following question based only on the provided context...\n",
        "        <context>{context}</context>\n",
        "        Question: {question}\"\"\"\n",
        "        final_prompt = ChatPromptTemplate.from_template(final_prompt_template)\n",
        "\n",
        "        def format_docs(docs: List[Document]) -> str:\n",
        "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "        context_formatter = (\n",
        "            RunnablePassthrough.assign(\n",
        "                context_str=itemgetter(\"context\") | RunnableLambda(format_docs)\n",
        "            )\n",
        "            | RunnableLambda(self._tap_and_log)\n",
        "        )        \n",
        "        \n",
        "        rag_chain = (\n",
        "            {\"context\": final_retrieval_chain, \"question\": RunnablePassthrough()}\n",
        "            | context_formatter\n",
        "            | {\n",
        "                  \"answer\": (\n",
        "                      lambda x: {\"context\": x[\"context_str\"], \"question\": x[\"question\"]}\n",
        "                  ) | final_prompt | self.llm | StrOutputParser(),\n",
        "                  \"context\": itemgetter(\"context\"),\n",
        "              }\n",
        "        )\n",
        "\n",
        "        result = rag_chain.invoke(question)\n",
        "\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": result['answer'],\n",
        "            \"strategy\": f\"{strategy} + {post_processing_strategy}\",\n",
        "            \"context\": result['context']\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4CRI_GB-btq",
        "outputId": "ee0ac2f7-0316-4a41-fdf4-728b32c3fb8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "--- Running with RAG strategy ---\n",
            "\n",
            "====================\n",
            "DEBUG: Contextual Compression Retriever\n",
            "====================\n",
            "'Initialized and ready.'\n",
            "\n",
            "====================\n",
            "DEBUG: Retrieved Documents (Simple)\n",
            "====================\n",
            "[Document(metadata={'id': 'pdf_doc_1_chunk_13_da6ca75b041245d18674dd726a03d374'}, page_content='the mmWave 14xx device). The accelerator is connected to a 128-bit bus that is present in the main\\nprocessor system, as shown in Figure 1.\\nThe Radar Hardware Accelerator module comprises an accelerator engine and four memories, each of\\n16KB size, which are used to send input data to and pull output data from the accelerator engine. These\\nmemories are referred to as local memories of the Radar Accelerator (ACCEL_MEM). For convenience,\\nthese four local memories are referred to as ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and\\nACCEL_MEM3.\\nFigure 1. Radar Hardware Accelerator (mmWave 14xx Device)www.ti.com Radar Hardware Accelerator – Overview\\n5SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\n1.3.1 High-Level Data Flow\\nThe typical data flow is that the DMA module is used to bring samples (for example, FFT input samples)'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_17_a063124a8ac7444e8ff0f5ccf5a1ed85'}, page_content='STATERRCODE register description in Table 3.\\nThe Radar Hardware Accelerator and the main processor (Cortex-R4F) in the mmWave 14xx device\\noperate on a single clock domain and the operating clock frequency is 200 MHz.\\nThe accelerator local memories are 128-bits wide, for example, each of the 16KB banks is implemented\\nas 1024 words of 128 bits each. This allows the DMA to bring data into the accelerator local memories\\nefficiently (up to a maximum throughput of 128 bits per clock cycle, depending upon the DMA\\nconfiguration).\\nIt is important to note that any of the four local memories can be the source of the input samples to the\\naccelerator engine and any of the four local memories can be the destination for the output samples from\\nthe accelerator engine – with the important restriction that the source and destination memories cannot be\\nthe same 16KB bank. Note also that the accelerator local memories do not necessarily need to be used in'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='the DMA and written back into the Radar data memory for further processing by the main processor.\\nNote that in the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single\\nchip along with the mmWave RF and analog front end. In this device, two of the accelerator local\\nmemories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC\\nbuffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are\\ndirectly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without\\nneeding a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the\\nactive transmission of chirps in a frame), it is possible to freely use these memories for second-dimension\\nFFT processing by bringing in data to these memories through DMA transfer.\\nThe purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_40_0d650815cc3a42b892ebe88f9a82d019'}, page_content='end of every chirp or at the end of every few chirps or at the end of every specified number of ADC\\nsamples. This mmWave 14xx digital front-end configuration is accomplished using other registers\\nunrelated to the Radar Hardware Accelerator and not described in this document.www.ti.com Accelerator Engine – State Machine\\n11SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\nNow, using this trigger mode (TRIGMODE = 010b) allows the accelerator computations to start\\nwhenever the ping-to-pong or pong-to-ping switch happens in the ADC buffer, thus enabling inline per-\\nchirp processing. It is important to mention here that the user must take care to ensure that processing\\nof the current ping data is completed by the accelerator, before the next switch/trigger happens on the\\nADC buffer. In other words, the chirp duration (ping-pong switch frequency) must be configured to be'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_51_d191c9094fe0456abdc12d45cea7588e'}, page_content='through which the state machine loops through. The state machine starts at the\\nparameter set specified by PARAMSTART and loads each parameter set one after\\nanother and runs the accelerator as per that configuration. When the state machine\\nreaches the parameter set specified by PARAMSTOP, it loops back to the start\\nindex as specified by PARAMSTART.\\nPARAMSTOP 4 No\\nFFT1DEN 1 No\\nADC buffer sharing mode (mmWave 14xx):\\nThis register is relevant in mmWave 14xx, where the Radar Hardware Accelerator is\\nincluded in a single device along with the mmWave RF front-end. In such a case,\\nduring active chirp transmission and inline first dimension FFT processing, the\\nACCEL_MEM0 and ACCEL_MEM1 memories of the accelerator are shared as ping-\\npong ADC buffers. This register bit needs to be set during this time, so that while the\\ndigital front end writes ADC samples to the ping buffer, the accelerator automatically\\naccesses (only) the pong buffer, and vice versa. At the end of the active'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_64_72f04cac09704a1daaf973f8bdc1dde5'}, page_content='they can be read as real samples or complex samples. These two aspects are configured using register\\nbits SRC16b32b and SRCREAL. See Table 2 for a description of these and other registers pertaining to\\nthe input formatter block. As an example, if SRC16b32b = 0 and SRCREAL = 0, then the input samples\\nare read from the memory as 16-bit complex samples (16-bit I and 16-bit Q), shown in Figure 6. In the\\nmmWave 14xx device, the ADC buffer is always filled with complex samples from the digital front end –\\nthis is true even if the device is configured for real-only operation, in which case the Q-channel output is\\nwritten with zero values. Therefore, for all purposes of part one of the user guide, SRCREAL can be\\nconfigured as 0.\\nAn important feature of the input formatter block is that it supports flexible access pattern to fetch data\\nfrom the source memory, which makes it convenient when the data corresponding to multiple RX channels'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_39_5a0077fef314477dac4cd5173546f6f2'}, page_content='the ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and\\nACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during\\nactive chirping portion of the frame. This sharing mode is enabled by setting the FFT1DEN register bit\\nbefore the start of the frame. In this trigger mode, the state machine of the accelerator starts the\\ncomputations for the current parameter set as soon as the ADC buffer switches from ping-to-pong or\\npong-to-ping. As an example, during the active chirping portion of a frame, the mmWave 14xx digital\\nfront end and ADC buffer can be configured to switch from ping-to-pong or pong-to-ping buffer at the\\nend of every chirp or at the end of every few chirps or at the end of every specified number of ADC\\nsamples. This mmWave 14xx digital front-end configuration is accomplished using other registers'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_38_7f8a7bb770fe4445baef375c726d9252'}, page_content='computations. In this trigger mode, the state machine waits for a software-based trigger, which involves\\nthe main processor setting a separate self-clearing bit in a CR42ACCTRIG register (single-bit register).\\nThe state machine keeps monitoring that register bit and waits as long as the value is zero. When the\\nvalue becomes 1 (set), the state machine gets triggered to start the accelerator operations for the\\ncurrent parameter set.\\n• Wait for the ADC buffer ping-to-pong or pong-to-ping switch (TRIGMODE = 010b): This trigger mode is\\nspecific to the mmWave 14xx device, which has RF and analog front end integrated in the same chip\\nwith the main processor and the Radar Hardware Accelerator. Recall that in the mmWave 14xx device,\\nthe ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and\\nACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_3_923b12fcbfa744f08854745a5f943067'}, page_content='List of Figures\\n1 Radar Hardware Accelerator (mmWave 14xx Device) ................................................................. 4\\n2 Accelerator Engine Block Diagram ........................................................................................ 6\\n3 Parameter-Set Configuration Memory (512 Bytes)...................................................................... 7\\n4 State Machine................................................................................................................ 9\\n5 Input Formatter ............................................................................................................. 15\\n6 Input Formatter Source Memory Access Pattern (Example) ......................................................... 17\\n7 Invalid Configuration Example ........................................................................................... 18'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_10_cd57b3cc0f1d4d0aad61dc9205171ec3'}, page_content='radar signal processing can be done within the Radar Hardware Accelerator, while still retaining the\\nflexibility of implementing other proprietary algorithms in the main processor.\\n1.2 Key Features\\nThe main features of the Radar Hardware Accelerator are as follows.\\n• Fast FFT computation, with programmable FFT sizes (powers of 2) up to 1024-pt complex FFT\\n• Internal FFT bit width of 24 bits (for each I and Q) for good SQNR performance, with fully\\nprogrammable butterfly scaling at every radix-2 stage for user flexibility\\n• Built-in capabilities for simple pre-FFT processing – specifically, programmable windowing, basic\\ninterference zeroing-out, and basic BPM removal\\n• Magnitude (absolute value) and log-magnitude computation capability\\n• Flexible data flow and data sample arrangement to support efficient multidimensional FFT operations\\nand transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with')]\n",
            "\n",
            "====================\n",
            "DEBUG: Documents going INTO Re-ranker (10 docs)\n",
            "====================\n",
            "[Document(metadata={'id': 'pdf_doc_1_chunk_13_da6ca75b041245d18674dd726a03d374'}, page_content='the mmWave 14xx device). The accelerator is connected to a 128-bit bus that is present in the main\\nprocessor system, as shown in Figure 1.\\nThe Radar Hardware Accelerator module comprises an accelerator engine and four memories, each of\\n16KB size, which are used to send input data to and pull output data from the accelerator engine. These\\nmemories are referred to as local memories of the Radar Accelerator (ACCEL_MEM). For convenience,\\nthese four local memories are referred to as ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and\\nACCEL_MEM3.\\nFigure 1. Radar Hardware Accelerator (mmWave 14xx Device)www.ti.com Radar Hardware Accelerator – Overview\\n5SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\n1.3.1 High-Level Data Flow\\nThe typical data flow is that the DMA module is used to bring samples (for example, FFT input samples)'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_17_a063124a8ac7444e8ff0f5ccf5a1ed85'}, page_content='STATERRCODE register description in Table 3.\\nThe Radar Hardware Accelerator and the main processor (Cortex-R4F) in the mmWave 14xx device\\noperate on a single clock domain and the operating clock frequency is 200 MHz.\\nThe accelerator local memories are 128-bits wide, for example, each of the 16KB banks is implemented\\nas 1024 words of 128 bits each. This allows the DMA to bring data into the accelerator local memories\\nefficiently (up to a maximum throughput of 128 bits per clock cycle, depending upon the DMA\\nconfiguration).\\nIt is important to note that any of the four local memories can be the source of the input samples to the\\naccelerator engine and any of the four local memories can be the destination for the output samples from\\nthe accelerator engine – with the important restriction that the source and destination memories cannot be\\nthe same 16KB bank. Note also that the accelerator local memories do not necessarily need to be used in'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='the DMA and written back into the Radar data memory for further processing by the main processor.\\nNote that in the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single\\nchip along with the mmWave RF and analog front end. In this device, two of the accelerator local\\nmemories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC\\nbuffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are\\ndirectly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without\\nneeding a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the\\nactive transmission of chirps in a frame), it is possible to freely use these memories for second-dimension\\nFFT processing by bringing in data to these memories through DMA transfer.\\nThe purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_40_0d650815cc3a42b892ebe88f9a82d019'}, page_content='end of every chirp or at the end of every few chirps or at the end of every specified number of ADC\\nsamples. This mmWave 14xx digital front-end configuration is accomplished using other registers\\nunrelated to the Radar Hardware Accelerator and not described in this document.www.ti.com Accelerator Engine – State Machine\\n11SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\nNow, using this trigger mode (TRIGMODE = 010b) allows the accelerator computations to start\\nwhenever the ping-to-pong or pong-to-ping switch happens in the ADC buffer, thus enabling inline per-\\nchirp processing. It is important to mention here that the user must take care to ensure that processing\\nof the current ping data is completed by the accelerator, before the next switch/trigger happens on the\\nADC buffer. In other words, the chirp duration (ping-pong switch frequency) must be configured to be'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_51_d191c9094fe0456abdc12d45cea7588e'}, page_content='through which the state machine loops through. The state machine starts at the\\nparameter set specified by PARAMSTART and loads each parameter set one after\\nanother and runs the accelerator as per that configuration. When the state machine\\nreaches the parameter set specified by PARAMSTOP, it loops back to the start\\nindex as specified by PARAMSTART.\\nPARAMSTOP 4 No\\nFFT1DEN 1 No\\nADC buffer sharing mode (mmWave 14xx):\\nThis register is relevant in mmWave 14xx, where the Radar Hardware Accelerator is\\nincluded in a single device along with the mmWave RF front-end. In such a case,\\nduring active chirp transmission and inline first dimension FFT processing, the\\nACCEL_MEM0 and ACCEL_MEM1 memories of the accelerator are shared as ping-\\npong ADC buffers. This register bit needs to be set during this time, so that while the\\ndigital front end writes ADC samples to the ping buffer, the accelerator automatically\\naccesses (only) the pong buffer, and vice versa. At the end of the active'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_64_72f04cac09704a1daaf973f8bdc1dde5'}, page_content='they can be read as real samples or complex samples. These two aspects are configured using register\\nbits SRC16b32b and SRCREAL. See Table 2 for a description of these and other registers pertaining to\\nthe input formatter block. As an example, if SRC16b32b = 0 and SRCREAL = 0, then the input samples\\nare read from the memory as 16-bit complex samples (16-bit I and 16-bit Q), shown in Figure 6. In the\\nmmWave 14xx device, the ADC buffer is always filled with complex samples from the digital front end –\\nthis is true even if the device is configured for real-only operation, in which case the Q-channel output is\\nwritten with zero values. Therefore, for all purposes of part one of the user guide, SRCREAL can be\\nconfigured as 0.\\nAn important feature of the input formatter block is that it supports flexible access pattern to fetch data\\nfrom the source memory, which makes it convenient when the data corresponding to multiple RX channels'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_39_5a0077fef314477dac4cd5173546f6f2'}, page_content='the ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and\\nACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during\\nactive chirping portion of the frame. This sharing mode is enabled by setting the FFT1DEN register bit\\nbefore the start of the frame. In this trigger mode, the state machine of the accelerator starts the\\ncomputations for the current parameter set as soon as the ADC buffer switches from ping-to-pong or\\npong-to-ping. As an example, during the active chirping portion of a frame, the mmWave 14xx digital\\nfront end and ADC buffer can be configured to switch from ping-to-pong or pong-to-ping buffer at the\\nend of every chirp or at the end of every few chirps or at the end of every specified number of ADC\\nsamples. This mmWave 14xx digital front-end configuration is accomplished using other registers'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_38_7f8a7bb770fe4445baef375c726d9252'}, page_content='computations. In this trigger mode, the state machine waits for a software-based trigger, which involves\\nthe main processor setting a separate self-clearing bit in a CR42ACCTRIG register (single-bit register).\\nThe state machine keeps monitoring that register bit and waits as long as the value is zero. When the\\nvalue becomes 1 (set), the state machine gets triggered to start the accelerator operations for the\\ncurrent parameter set.\\n• Wait for the ADC buffer ping-to-pong or pong-to-ping switch (TRIGMODE = 010b): This trigger mode is\\nspecific to the mmWave 14xx device, which has RF and analog front end integrated in the same chip\\nwith the main processor and the Radar Hardware Accelerator. Recall that in the mmWave 14xx device,\\nthe ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and\\nACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_3_923b12fcbfa744f08854745a5f943067'}, page_content='List of Figures\\n1 Radar Hardware Accelerator (mmWave 14xx Device) ................................................................. 4\\n2 Accelerator Engine Block Diagram ........................................................................................ 6\\n3 Parameter-Set Configuration Memory (512 Bytes)...................................................................... 7\\n4 State Machine................................................................................................................ 9\\n5 Input Formatter ............................................................................................................. 15\\n6 Input Formatter Source Memory Access Pattern (Example) ......................................................... 17\\n7 Invalid Configuration Example ........................................................................................... 18'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_10_cd57b3cc0f1d4d0aad61dc9205171ec3'}, page_content='radar signal processing can be done within the Radar Hardware Accelerator, while still retaining the\\nflexibility of implementing other proprietary algorithms in the main processor.\\n1.2 Key Features\\nThe main features of the Radar Hardware Accelerator are as follows.\\n• Fast FFT computation, with programmable FFT sizes (powers of 2) up to 1024-pt complex FFT\\n• Internal FFT bit width of 24 bits (for each I and Q) for good SQNR performance, with fully\\nprogrammable butterfly scaling at every radix-2 stage for user flexibility\\n• Built-in capabilities for simple pre-FFT processing – specifically, programmable windowing, basic\\ninterference zeroing-out, and basic BPM removal\\n• Magnitude (absolute value) and log-magnitude computation capability\\n• Flexible data flow and data sample arrangement to support efficient multidimensional FFT operations\\nand transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with')]\n",
            "\n",
            "====================\n",
            "DEBUG: Documents COMING OUT of Re-ranker (5 docs)\n",
            "====================\n",
            "[Document(metadata={'id': 'pdf_doc_1_chunk_13_da6ca75b041245d18674dd726a03d374'}, page_content='the mmWave 14xx device). The accelerator is connected to a 128-bit bus that is present in the main\\nprocessor system, as shown in Figure 1.\\nThe Radar Hardware Accelerator module comprises an accelerator engine and four memories, each of\\n16KB size, which are used to send input data to and pull output data from the accelerator engine. These\\nmemories are referred to as local memories of the Radar Accelerator (ACCEL_MEM). For convenience,\\nthese four local memories are referred to as ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and\\nACCEL_MEM3.\\nFigure 1. Radar Hardware Accelerator (mmWave 14xx Device)www.ti.com Radar Hardware Accelerator – Overview\\n5SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\n1.3.1 High-Level Data Flow\\nThe typical data flow is that the DMA module is used to bring samples (for example, FFT input samples)'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_17_a063124a8ac7444e8ff0f5ccf5a1ed85'}, page_content='STATERRCODE register description in Table 3.\\nThe Radar Hardware Accelerator and the main processor (Cortex-R4F) in the mmWave 14xx device\\noperate on a single clock domain and the operating clock frequency is 200 MHz.\\nThe accelerator local memories are 128-bits wide, for example, each of the 16KB banks is implemented\\nas 1024 words of 128 bits each. This allows the DMA to bring data into the accelerator local memories\\nefficiently (up to a maximum throughput of 128 bits per clock cycle, depending upon the DMA\\nconfiguration).\\nIt is important to note that any of the four local memories can be the source of the input samples to the\\naccelerator engine and any of the four local memories can be the destination for the output samples from\\nthe accelerator engine – with the important restriction that the source and destination memories cannot be\\nthe same 16KB bank. Note also that the accelerator local memories do not necessarily need to be used in'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='the DMA and written back into the Radar data memory for further processing by the main processor.\\nNote that in the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single\\nchip along with the mmWave RF and analog front end. In this device, two of the accelerator local\\nmemories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC\\nbuffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are\\ndirectly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without\\nneeding a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the\\nactive transmission of chirps in a frame), it is possible to freely use these memories for second-dimension\\nFFT processing by bringing in data to these memories through DMA transfer.\\nThe purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_64_72f04cac09704a1daaf973f8bdc1dde5'}, page_content='they can be read as real samples or complex samples. These two aspects are configured using register\\nbits SRC16b32b and SRCREAL. See Table 2 for a description of these and other registers pertaining to\\nthe input formatter block. As an example, if SRC16b32b = 0 and SRCREAL = 0, then the input samples\\nare read from the memory as 16-bit complex samples (16-bit I and 16-bit Q), shown in Figure 6. In the\\nmmWave 14xx device, the ADC buffer is always filled with complex samples from the digital front end –\\nthis is true even if the device is configured for real-only operation, in which case the Q-channel output is\\nwritten with zero values. Therefore, for all purposes of part one of the user guide, SRCREAL can be\\nconfigured as 0.\\nAn important feature of the input formatter block is that it supports flexible access pattern to fetch data\\nfrom the source memory, which makes it convenient when the data corresponding to multiple RX channels'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_38_7f8a7bb770fe4445baef375c726d9252'}, page_content='computations. In this trigger mode, the state machine waits for a software-based trigger, which involves\\nthe main processor setting a separate self-clearing bit in a CR42ACCTRIG register (single-bit register).\\nThe state machine keeps monitoring that register bit and waits as long as the value is zero. When the\\nvalue becomes 1 (set), the state machine gets triggered to start the accelerator operations for the\\ncurrent parameter set.\\n• Wait for the ADC buffer ping-to-pong or pong-to-ping switch (TRIGMODE = 010b): This trigger mode is\\nspecific to the mmWave 14xx device, which has RF and analog front end integrated in the same chip\\nwith the main processor and the Radar Hardware Accelerator. Recall that in the mmWave 14xx device,\\nthe ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and\\nACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during')]\n",
            "\n",
            "====================\n",
            "DEBUG: Final Context for LLM\n",
            "====================\n",
            "('the mmWave 14xx device). The Radar Hardware Accelerator module comprises an '\n",
            " 'accelerator engine and four memories, each of 16KB size, which are used to '\n",
            " 'send input data to and pull output data from the accelerator engine. These '\n",
            " 'memories are referred to as local memories of the Radar Accelerator '\n",
            " '(ACCEL_MEM). For convenience, these four local memories are referred to as '\n",
            " 'ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and ACCEL_MEM3.\\n'\n",
            " '\\n'\n",
            " 'The Radar Hardware Accelerator and the main processor (Cortex-R4F) in the '\n",
            " 'mmWave 14xx device operate on a single clock domain and the operating clock '\n",
            " 'frequency is 200 MHz. The accelerator local memories are 128-bits wide, for '\n",
            " 'example, each of the 16KB banks is implemented as 1024 words of 128 bits '\n",
            " 'each. This allows the DMA to bring data into the accelerator local memories '\n",
            " 'efficiently (up to a maximum throughput of 128 bits per clock cycle, '\n",
            " 'depending upon the DMA configuration). It is important to note that any of '\n",
            " 'the four local memories can be the source of the input samples to the '\n",
            " 'accelerator engine and any of the four local memories can be the destination '\n",
            " 'for the output samples from the accelerator engine – with the important '\n",
            " 'restriction that the source and destination memories cannot be the same 16KB '\n",
            " 'bank.\\n'\n",
            " '\\n'\n",
            " 'In the mmWave 14xx device, the Radar Hardware Accelerator is included as '\n",
            " 'part of a single chip along with the mmWave RF and analog front end. In this '\n",
            " 'device, two of the accelerator local memories, namely ACCEL_MEM0 and '\n",
            " 'ACCEL_MEM1, are directly shared with the ping and pong ADC buffers (which '\n",
            " 'are 16KB each) – such that the ADC output samples for first-dimension FFT '\n",
            " 'processing are directly and immediately available to the Radar Hardware '\n",
            " 'Accelerator at the end of each chirp, without needing a DMA transfer. After '\n",
            " 'the first-dimension FFT processing is complete (typically, at the end of the '\n",
            " 'active transmission of chirps in a frame), it is possible to freely use '\n",
            " 'these memories for second-dimension FFT processing by bringing in data to '\n",
            " 'these memories through DMA transfer. The purpose behind the four separate '\n",
            " 'local memories (16KB each) inside the Radar Hardware Accelerator.\\n'\n",
            " '\\n'\n",
            " 'they can be read as real samples or complex samples. These two aspects are '\n",
            " 'configured using register bits SRC16b32b and SRCREAL. See Table 2 for a '\n",
            " 'description of these and other registers pertaining to the input formatter '\n",
            " 'block. As an example, if SRC16b32b = 0 and SRCREAL = 0, then the input '\n",
            " 'samples are read from the memory as 16-bit complex samples (16-bit I and '\n",
            " '16-bit Q), shown in Figure 6. In the mmWave 14xx device, the ADC buffer is '\n",
            " 'always filled with complex samples from the digital front end – this is true '\n",
            " 'even if the device is configured for real-only operation, in which case the '\n",
            " 'Q-channel output is written with zero values. Therefore, for all purposes of '\n",
            " 'part one of the user guide, SRCREAL can be configured as 0. An important '\n",
            " 'feature of the input formatter block is that it supports flexible access '\n",
            " 'pattern to fetch data from the source memory, which makes it convenient when '\n",
            " 'the data corresponding to multiple RX channels\\n'\n",
            " '\\n'\n",
            " '• Wait for the ADC buffer ping-to-pong or pong-to-ping switch (TRIGMODE = '\n",
            " '010b): This trigger mode is specific to the mmWave 14xx device, which has RF '\n",
            " 'and analog front end integrated in the same chip with the main processor and '\n",
            " 'the Radar Hardware Accelerator. Recall that in the mmWave 14xx device, the '\n",
            " 'ADC ping and pong buffers are shared with the accelerator local memories '\n",
            " '(ACCEL_MEM0 and ACCEL_MEM1), such that the ADC data is directly available to '\n",
            " 'the accelerator for processing during')\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "{'answer': 'The key features of the mmWave 14xx devices include:\\n'\n",
            "           '\\n'\n",
            "           '1. **Integrated Radar Hardware Accelerator**: The device includes '\n",
            "           'a Radar Hardware Accelerator that features an accelerator engine '\n",
            "           'and four local memories (ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and '\n",
            "           'ACCEL_MEM3), each with a capacity of 16KB.\\n'\n",
            "           '\\n'\n",
            "           '2. **Shared Memories with ADC Buffers**: Two of the accelerator '\n",
            "           'local memories (ACCEL_MEM0 and ACCEL_MEM1) are shared with the ADC '\n",
            "           'ping and pong buffers, allowing for immediate access to ADC output '\n",
            "           'samples for processing without needing a DMA transfer.\\n'\n",
            "           '\\n'\n",
            "           '3. **High Operating Frequency**: The device operates on a single '\n",
            "           'clock domain at a frequency of 200 MHz.\\n'\n",
            "           '\\n'\n",
            "           '4. **DMA Support**: The local memories are designed for efficient '\n",
            "           'data transfer, enabling a maximum throughput of 128 bits per clock '\n",
            "           'cycle, depending on DMA configuration.\\n'\n",
            "           '\\n'\n",
            "           '5. **Flexible Data Access**: The input formatter block supports '\n",
            "           'flexible access patterns to fetch data from the source memory, '\n",
            "           'accommodating various needs during processing.\\n'\n",
            "           '\\n'\n",
            "           '6. **Complex Sample Support**: The device processes input as '\n",
            "           'either real or complex samples, with configuration options '\n",
            "           'available via certain registers (SRC16b32b and SRCREAL).\\n'\n",
            "           '\\n'\n",
            "           '7. **Direct ADC Integration**: The ADC buffers are filled with '\n",
            "           'complex samples, ensuring that processed data is always available '\n",
            "           'in the correct format, while also allowing for real-only operation '\n",
            "           'when needed.\\n'\n",
            "           '\\n'\n",
            "           'These features collectively enhance the performance and '\n",
            "           'flexibility of the mmWave 14xx devices in radar applications.',\n",
            " 'context': [Document(metadata={'id': 'pdf_doc_1_chunk_13_da6ca75b041245d18674dd726a03d374'}, page_content='the mmWave 14xx device). The Radar Hardware Accelerator module comprises an accelerator engine and four memories, each of 16KB size, which are used to send input data to and pull output data from the accelerator engine. These memories are referred to as local memories of the Radar Accelerator (ACCEL_MEM). For convenience, these four local memories are referred to as ACCEL_MEM0, ACCEL_MEM1, ACCEL_MEM2, and ACCEL_MEM3.'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_17_a063124a8ac7444e8ff0f5ccf5a1ed85'}, page_content='The Radar Hardware Accelerator and the main processor (Cortex-R4F) in the mmWave 14xx device operate on a single clock domain and the operating clock frequency is 200 MHz. The accelerator local memories are 128-bits wide, for example, each of the 16KB banks is implemented as 1024 words of 128 bits each. This allows the DMA to bring data into the accelerator local memories efficiently (up to a maximum throughput of 128 bits per clock cycle, depending upon the DMA configuration). It is important to note that any of the four local memories can be the source of the input samples to the accelerator engine and any of the four local memories can be the destination for the output samples from the accelerator engine – with the important restriction that the source and destination memories cannot be the same 16KB bank.'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='In the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single chip along with the mmWave RF and analog front end. In this device, two of the accelerator local memories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC buffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are directly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without needing a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the active transmission of chirps in a frame), it is possible to freely use these memories for second-dimension FFT processing by bringing in data to these memories through DMA transfer. The purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator.'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_64_72f04cac09704a1daaf973f8bdc1dde5'}, page_content='they can be read as real samples or complex samples. These two aspects are configured using register bits SRC16b32b and SRCREAL. See Table 2 for a description of these and other registers pertaining to the input formatter block. As an example, if SRC16b32b = 0 and SRCREAL = 0, then the input samples are read from the memory as 16-bit complex samples (16-bit I and 16-bit Q), shown in Figure 6. In the mmWave 14xx device, the ADC buffer is always filled with complex samples from the digital front end – this is true even if the device is configured for real-only operation, in which case the Q-channel output is written with zero values. Therefore, for all purposes of part one of the user guide, SRCREAL can be configured as 0. An important feature of the input formatter block is that it supports flexible access pattern to fetch data from the source memory, which makes it convenient when the data corresponding to multiple RX channels'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_38_7f8a7bb770fe4445baef375c726d9252'}, page_content='• Wait for the ADC buffer ping-to-pong or pong-to-ping switch (TRIGMODE = 010b): This trigger mode is specific to the mmWave 14xx device, which has RF and analog front end integrated in the same chip with the main processor and the Radar Hardware Accelerator. Recall that in the mmWave 14xx device, the ADC ping and pong buffers are shared with the accelerator local memories (ACCEL_MEM0 and ACCEL_MEM1), such that the ADC data is directly available to the accelerator for processing during')],\n",
            " 'question': 'What are the key features of the 14xx mmWave devices?',\n",
            " 'strategy': 'simple + semantic_re_ranking+contextual_compression'}\n",
            "\n",
            "\n",
            "--- Running with LLM Only Strategy ---\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "{'answer': 'The 14xx mmWave devices, often referring to a category of '\n",
            "           'millimeter wave technology used in various applications such as '\n",
            "           'telecommunications, radar systems, and related fields, typically '\n",
            "           'exhibit several key features:\\n'\n",
            "           '\\n'\n",
            "           '1. **High Frequency Range**: 14xx mmWave devices operate in the '\n",
            "           'millimeter wave frequency bands, generally spanning from 14 GHz to '\n",
            "           '14.5 GHz, allowing for high data rates and bandwidth.\\n'\n",
            "           '\\n'\n",
            "           '2. **High Data Rates**: These devices can deliver very high data '\n",
            "           'throughput, making them suitable for applications requiring low '\n",
            "           'latency and high-speed data transmission, such as 5G networks and '\n",
            "           'advanced wireless communications.\\n'\n",
            "           '\\n'\n",
            "           '3. **Short-Range Communication**: Due to the nature of mmWave '\n",
            "           'frequencies, these devices are optimized for short-range '\n",
            "           'applications. They are typically used in scenarios where direct '\n",
            "           'line-of-sight communication is achievable.\\n'\n",
            "           '\\n'\n",
            "           '4. **Beamforming Capabilities**: Many 14xx mmWave devices '\n",
            "           'incorporate advanced beamforming technology to enhance signal '\n",
            "           'strength and reduce interference, allowing for improved '\n",
            "           'connectivity in crowded environments.\\n'\n",
            "           '\\n'\n",
            "           '5. **High Precision and Resolution**: The high frequencies enable '\n",
            "           'enhanced resolution for applications like radar and sensing, '\n",
            "           'making these devices ideal for detailed imaging and data '\n",
            "           'collection.\\n'\n",
            "           '\\n'\n",
            "           '6. **Integration with Other Technologies**: 14xx mmWave devices '\n",
            "           'often support integration with other technologies, such as MIMO '\n",
            "           '(Multiple Input Multiple Output) systems, enhancing their '\n",
            "           'effectiveness in complex environments.\\n'\n",
            "           '\\n'\n",
            "           '7. **Enhanced Security**: Operating at higher frequencies allows '\n",
            "           'for more secure communications, as the signal behavior is less '\n",
            "           'susceptible to interception and can be more easily concentrated in '\n",
            "           'a specific direction.\\n'\n",
            "           '\\n'\n",
            "           '8. **Multi-Channel Operation**: Many devices support multiple '\n",
            "           'channels or sub-bands within the mmWave spectrum, allowing for '\n",
            "           'increased capacity and flexibility in data handling and frequency '\n",
            "           'allocation.\\n'\n",
            "           '\\n'\n",
            "           '9. **Power Efficiency**: Recent advancements focus on creating '\n",
            "           'mmWave devices that are power-efficient, which is critical for the '\n",
            "           'deployment of these technologies in mobile and battery-operated '\n",
            "           'devices.\\n'\n",
            "           '\\n'\n",
            "           '10. **Compact Form Factor**: Advances in technology have allowed '\n",
            "           'for the miniaturization of mmWave components, resulting in '\n",
            "           'smaller, lighter devices that are easier to deploy in various '\n",
            "           'settings.\\n'\n",
            "           '\\n'\n",
            "           '11. **Robustness Against Interference**: These devices often show '\n",
            "           'improved performance in noisy environments, making them suitable '\n",
            "           'for use in urban areas with many competing signals.\\n'\n",
            "           '\\n'\n",
            "           '12. **Support for Advanced Modulation Techniques**: 14xx mmWave '\n",
            "           'devices are generally compatible with advanced modulation schemes, '\n",
            "           'further enhancing their throughput capabilities.\\n'\n",
            "           '\\n'\n",
            "           'These features make 14xx mmWave devices a significant component of '\n",
            "           'next-generation communication systems, radar technologies, and '\n",
            "           'various applications in the Internet of Things (IoT).',\n",
            " 'context': 'N/A',\n",
            " 'question': 'What are the key features of the 14xx mmWave devices?',\n",
            " 'strategy': 'llm_only'}\n"
          ]
        }
      ],
      "source": [
        "# --- Example Usage ---\n",
        "# main.py\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Get API keys using using dotenv\n",
        "load_dotenv()\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY_SHIVAM\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get API keys using google.colab\n",
        "# from google.colab import userdata\n",
        "# OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# PINECONE_API_KEY = userdata.get('PINECONE_API_KEY_SHIVAM')\n",
        "\n",
        "\n",
        "# --- Example 1: RAG Fusion with Debugging Enabled ---\n",
        "print(\"\\n\\n\" + \"--- Running with RAG strategy ---\")\n",
        "config = {\n",
        "    \"llm_model\": \"gpt-4o-mini\",\n",
        "    \"retrieval_strategy\": \"simple\",\n",
        "    \"post_retrieval_processing\": \"semantic_re_ranking+contextual_compression\",\n",
        "    \"index_name\": \"swru526-pine\",\n",
        "    \"namespace\": \"example-namespace\",\n",
        "    \"top_k\": 10,\n",
        "    \"reranker_top_n\": 5,  # This is for the re-ranker, if used\n",
        "    \"debug\": True  # <-- Enable debugging\n",
        "}\n",
        "\n",
        "orchestrator_RAG = RAGOrchestrator(config)\n",
        "question = \"What are the key features of the 14xx mmWave devices?\"\n",
        "result_RAG = orchestrator_RAG.invoke(question)\n",
        "print(\"\\n--- FINAL OUTPUT ---\")\n",
        "pprint(result_RAG)\n",
        "\n",
        "\n",
        "# --- Example 2: LLM Only (No RAG) via Config ---\n",
        "print(\"\\n\\n\" + \"--- Running with LLM Only Strategy ---\")\n",
        "llm_only_config = {\n",
        "    \"llm_model\": \"gpt-4o-mini\",\n",
        "    \"retrieval_strategy\": \"llm_only\",\n",
        "    \"debug\": False # Debug flag works here too\n",
        "}\n",
        "\n",
        "orchestrator_llm_only = RAGOrchestrator(llm_only_config)\n",
        "result_llm_only = orchestrator_llm_only.invoke(question)\n",
        "print(\"\\n--- FINAL OUTPUT ---\")\n",
        "pprint(result_llm_only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXmKoJU9jJqj"
      },
      "outputs": [],
      "source": [
        "# 1. Core Retrieval Strategy\n",
        "# This is the main method used to find and fetch the initial set of documents.\n",
        "#     \"simple\": A single vector search against the user's query.\n",
        "#     \"multi_query\": Generates multiple variations of the query and combines the results (unique union).\n",
        "#     \"rag_fusion\": Generates multiple variations of the query and combines the results using Reciprocal Rank Fusion.\n",
        "#     \"decomposition\": Breaks a complex query into sub-questions and retrieves for each.\n",
        "#     \"step_back\": Asks a more general question to get broader context.\n",
        "#     \"hyde\": Generates a hypothetical document to guide the search.\n",
        "#     \"llm_only\": No retrieval at all.\n",
        "\n",
        "# 2. Post-Retrieval Processing\n",
        "# This defines what happens to the documents after they are retrieved but before they are sent to the LLM.\n",
        "#     \"none\": No processing; use the documents as-is.\n",
        "#     \"semantic_re_ranking\": Use a more powerful Cross-Encoder to re-rank the documents for semantic relevance.\n",
        "\n",
        "# 3. Final Prompting Strategy\n",
        "# This determines how the LLM is instructed to use the context to formulate the final answer.\n",
        "#     \"strict_context\": The prompt will strictly forbid the LLM from using any knowledge outside of the provided documents.\n",
        "#     \"permissive_context\": The prompt will encourage the LLM to primarily use the context but allow it to synthesize an answer using its general knowledge if needed.\n",
        "\n",
        "# 4. General Parameters\n",
        "# These are the basic \"knobs\" for any given run.\n",
        "#     \"llm_model\": e.g., \"gpt-4o-mini\", \"gpt-4o\"\n",
        "#     \"index_name\": The specific Pinecone index to target.\n",
        "#     \"namespace\": The namespace within that index.\n",
        "#     \"top_k\": The number of documents to retrieve initially.\n",
        "#     \"debug\": True or False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. BEFORE COMPRESSION ---\n",
            "Running the base retriever alone...\n",
            "\n",
            "(Base retriever was called and found 3 initial documents...)\n",
            "[Document(metadata={'source': 'doc-A', 'chunk': 1}, page_content='The AWR2944 device features a high-performance Radar Hardware Accelerator (HWA 2.0). It is designed for low-power applications and supports up to four transmitting antennas for advanced sensing.'),\n",
            " Document(metadata={'source': 'doc-B', 'chunk': 45}, page_content='General system design requires careful power management. The main processor, a Cortex-R4F, operates at 200 MHz, while the HWA 2.0 handles all FFT processing.'),\n",
            " Document(metadata={'source': 'doc-C', 'chunk': 102}, page_content='For marketing and sales inquiries, please contact our regional offices in North America and Europe. Our headquarters are located in Dallas, Texas.')]\n",
            "\n",
            "Number of documents: 3\n",
            "\n",
            "============================================================\n",
            "\n",
            "--- 2. AFTER COMPRESSION ---\n",
            "Running the ContextualCompressionRetriever...\n",
            "\n",
            "(Base retriever was called and found 3 initial documents...)\n",
            "[Document(metadata={'source': 'doc-A', 'chunk': 1}, page_content='The AWR2944 device features a high-performance Radar Hardware Accelerator (HWA 2.0). It is designed for low-power applications and supports up to four transmitting antennas for advanced sensing.')]\n",
            "\n",
            "Number of documents: 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pprint import pprint\n",
        "from typing import List\n",
        "\n",
        "# --- Necessary LangChain Imports ---\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.documents import Document\n",
        "from langchain.schema import BaseRetriever\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "# --- Setup API Keys (ensure your .env file is correct) ---\n",
        "load_dotenv()\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# --- 1. Create a Fake Retriever for this Example ---\n",
        "# This simulates your base retriever (e.g., from Pinecone)\n",
        "# It will always return the same three documents.\n",
        "class FakeRetriever(BaseRetriever):\n",
        "    \"\"\"A simple retriever that returns a hardcoded list of documents for demonstration.\"\"\"\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        print(\"(Base retriever was called and found 3 initial documents...)\")\n",
        "        return [\n",
        "            Document(\n",
        "                page_content=\"The AWR2944 device features a high-performance Radar Hardware Accelerator (HWA 2.0). It is designed for low-power applications and supports up to four transmitting antennas for advanced sensing.\",\n",
        "                metadata={\"source\": \"doc-A\", \"chunk\": 1}\n",
        "            ),\n",
        "            Document(\n",
        "                page_content=\"General system design requires careful power management. The main processor, a Cortex-R4F, operates at 200 MHz, while the HWA 2.0 handles all FFT processing.\",\n",
        "                metadata={\"source\": \"doc-B\", \"chunk\": 45}\n",
        "            ),\n",
        "            Document(\n",
        "                page_content=\"For marketing and sales inquiries, please contact our regional offices in North America and Europe. Our headquarters are located in Dallas, Texas.\",\n",
        "                metadata={\"source\": \"doc-C\", \"chunk\": 102}\n",
        "            )\n",
        "        ]\n",
        "    \n",
        "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        return self._get_relevant_documents(query)\n",
        "\n",
        "# --- 2. Define the Components ---\n",
        "\n",
        "# The user's question we will test with\n",
        "query = \"Tell me about the Radar Hardware Accelerator\"\n",
        "\n",
        "# Initialize our base retriever\n",
        "base_retriever = FakeRetriever()\n",
        "\n",
        "# Initialize the LLM that will be used for extraction\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Initialize the compressor component\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "\n",
        "# Create the final compression retriever, wrapping the base retriever and compressor\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")\n",
        "\n",
        "# --- 3. Run and Compare the Outputs ---\n",
        "\n",
        "print(\"--- 1. BEFORE COMPRESSION ---\")\n",
        "print(\"Running the base retriever alone...\\n\")\n",
        "uncompressed_docs = base_retriever.invoke(query)\n",
        "pprint(uncompressed_docs)\n",
        "print(f\"\\nNumber of documents: {len(uncompressed_docs)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "print(\"--- 2. AFTER COMPRESSION ---\")\n",
        "print(\"Running the ContextualCompressionRetriever...\\n\")\n",
        "# This will first call the base_retriever, then run the compressor on its results\n",
        "compressed_docs = compression_retriever.invoke(query)\n",
        "pprint(compressed_docs)\n",
        "print(f\"\\nNumber of documents: {len(compressed_docs)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
