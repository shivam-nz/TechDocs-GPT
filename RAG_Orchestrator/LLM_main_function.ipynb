{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBi4XNKKyESx",
        "outputId": "3f869c35-4f3a-4336-e87d-e55c57ab5159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in c:\\program files\\python311\\lib\\site-packages (0.4.8)\n",
            "Requirement already satisfied: langsmith in c:\\program files\\python311\\lib\\site-packages (0.3.45)\n",
            "Requirement already satisfied: langchain in c:\\program files\\python311\\lib\\site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain_community in c:\\program files\\python311\\lib\\site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core>=0.1 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (2.11.5)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith) (1.26.15)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\program files\\python311\\lib\\site-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\program files\\python311\\lib\\site-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in c:\\program files\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (3.12.12)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in c:\\program files\\python311\\lib\\site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\program files\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\program files\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\program files\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\program files\\python311\\lib\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu in c:\\program files\\python311\\lib\\site-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\program files\\python311\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python311\\lib\\site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: sentence-transformers in c:\\program files\\python311\\lib\\site-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: tqdm in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (2.7.0+cu128)\n",
            "Requirement already satisfied: scikit-learn in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (9.5.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\program files\\python311\\lib\\site-packages (from sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\program files\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\program files\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\program files\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\program files\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: langchain-huggingface in c:\\program files\\python311\\lib\\site-packages (0.3.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.3.65)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-huggingface) (0.33.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.13.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.26.15)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.30.2->langchain-huggingface) (0.4.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: langchain-google-genai in c:\\program files\\python311\\lib\\site-packages (2.1.5)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.62 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (0.3.65)\n",
            "Requirement already satisfied: pydantic<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langchain-google-genai) (2.11.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.17.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\program files\\python311\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.31.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\program files\\python311\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\program files\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\program files\\python311\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.13.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.15)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\program files\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<0.4.0,>=0.3.62->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: langchain_openai in c:\\program files\\python311\\lib\\site-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (0.3.65)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (1.88.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\program files\\python311\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.13.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in c:\\program files\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.11.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\program files\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: anyio in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\program files\\python311\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai) (1.26.15)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\program files\\python311\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
            "Requirement already satisfied: openai in c:\\program files\\python311\\lib\\site-packages (1.88.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\program files\\python311\\lib\\site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in c:\\program files\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\program files\\python311\\lib\\site-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\program files\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: certifi in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\program files\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\program files\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\program files\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: pinecone in c:\\program files\\python311\\lib\\site-packages (7.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (2022.12.7)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (4.13.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\program files\\python311\\lib\\site-packages (from pinecone) (1.26.15)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\program files\\python311\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\program files\\python311\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\program files\\python311\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
            "Requirement already satisfied: flashrank in c:\\program files\\python311\\lib\\site-packages (0.2.10)\n",
            "Requirement already satisfied: tokenizers in c:\\program files\\python311\\lib\\site-packages (from flashrank) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime in c:\\program files\\python311\\lib\\site-packages (from flashrank) (1.22.0)\n",
            "Requirement already satisfied: numpy in c:\\program files\\python311\\lib\\site-packages (from flashrank) (1.26.4)\n",
            "Requirement already satisfied: requests in c:\\program files\\python311\\lib\\site-packages (from flashrank) (2.32.4)\n",
            "Requirement already satisfied: tqdm in c:\\program files\\python311\\lib\\site-packages (from flashrank) (4.67.1)\n",
            "Requirement already satisfied: coloredlogs in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (23.3.3)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (24.2)\n",
            "Requirement already satisfied: protobuf in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (6.31.1)\n",
            "Requirement already satisfied: sympy in c:\\program files\\python311\\lib\\site-packages (from onnxruntime->flashrank) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\program files\\python311\\lib\\site-packages (from coloredlogs->onnxruntime->flashrank) (10.0)\n",
            "Requirement already satisfied: pyreadline3 in c:\\program files\\python311\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime->flashrank) (3.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python311\\lib\\site-packages (from requests->flashrank) (2022.12.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\program files\\python311\\lib\\site-packages (from sympy->onnxruntime->flashrank) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\program files\\python311\\lib\\site-packages (from tokenizers->flashrank) (0.33.0)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\program files\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (4.13.0)\n",
            "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from tqdm->flashrank) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "# @title Default title text\n",
        "!pip install langgraph langsmith langchain langchain_community\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers\n",
        "!pip install -U langchain-huggingface\n",
        "!pip install -U langchain-google-genai\n",
        "!pip install -U langchain_openai\n",
        "!pip install -U openai\n",
        "!pip install -U pinecone\n",
        "!pip install flashrank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9JnlZTf-btn"
      },
      "source": [
        "## PINECONE DB RETRIEVER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yMo-66Ei-bto"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pinecone import Pinecone\n",
        "from typing import List, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain.schema import BaseRetriever, Document\n",
        "from langchain.load import dumps, loads\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "class PineconeDBRetriever(BaseRetriever, BaseModel):\n",
        "    \"\"\"\n",
        "    A custom LangChain retriever for Pinecone.\n",
        "    \"\"\"\n",
        "    index_name: str\n",
        "    pinecone_api_key: str\n",
        "    namespace: str\n",
        "    top_k: int = 5\n",
        "    index: Any = Field(None, exclude=True)\n",
        "\n",
        "    def __init__(self, **data):\n",
        "        \"\"\"\n",
        "        Initializes the Pinecone client and index.\n",
        "        \"\"\"\n",
        "        super().__init__(**data)\n",
        "        pc = Pinecone(api_key=self.pinecone_api_key)\n",
        "        self.index = pc.Index(self.index_name)\n",
        "\n",
        "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        The core method to retrieve documents. LangChain's retriever system\n",
        "        calls this method.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's question.\n",
        "\n",
        "        Returns:\n",
        "            List[Document]: A list of relevant documents from Pinecone.\n",
        "        \"\"\"\n",
        "        # Pinecone's hosted embedding model will automatically embed the query text.\n",
        "        results = self.index.search(\n",
        "            namespace=self.namespace,\n",
        "            query={\n",
        "                \"inputs\": {\"text\": query},\n",
        "                \"top_k\": self.top_k\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Convert Pinecone's search results into LangChain Document objects.\n",
        "        # TODO: Add additional fields as necessary.\n",
        "        documents = []\n",
        "        if results and 'result' in results and 'hits' in results['result']:\n",
        "            for match in results['result']['hits']:\n",
        "                # The actual text content is in the 'fields' dictionary\n",
        "                page_content = match.get('fields', {}).get('text', '')\n",
        "                # metadata = {\"id\": match.get(\"_id\"), \"score\": match.get(\"_score\")}\n",
        "                metadata = {\"id\": match.get(\"_id\")} # Removing score to allow easy serialization and help de-duplication\n",
        "\n",
        "                doc = Document(\n",
        "                    page_content=page_content,\n",
        "                    metadata=metadata\n",
        "                )\n",
        "                documents.append(doc)\n",
        "\n",
        "        return documents\n",
        "\n",
        "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Asynchronous version of the document retrieval method.\n",
        "        \"\"\"\n",
        "        # For simplicity, we'll just call the synchronous version.\n",
        "        # For a production environment, you might want to use an async Pinecone client.\n",
        "        return self._get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D33r0fv9-btp"
      },
      "source": [
        "## RAG ORCHESTRATOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DpJuH5l9-btp"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pprint import pprint\n",
        "from typing import Any, List\n",
        "from langchain.load import dumps, loads\n",
        "\n",
        "class RAGOrchestrator:\n",
        "    \"\"\"\n",
        "    Orchestrates the RAG pipeline based on a given configuration.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: dict):\n",
        "        \"\"\"\n",
        "        Initializes the orchestrator with a configuration dictionary.\n",
        "\n",
        "        Args:\n",
        "            config (dict): A dictionary containing settings for the RAG pipeline,\n",
        "                           such as model name, index name, and retrieval strategy.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.debug = config.get(\"debug\", False)\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=config.get(\"llm_model\", \"gpt-4o-mini\"),\n",
        "            api_key=OPENAI_API_KEY\n",
        "        )\n",
        "        if config.get(\"retrieval_strategy\") != \"llm_only\":\n",
        "            self.retriever = PineconeDBRetriever(\n",
        "                index_name=config.get(\"index_name\"),\n",
        "                pinecone_api_key=PINECONE_API_KEY,\n",
        "                namespace=config.get(\"namespace\"),\n",
        "                top_k=config.get(\"top_k\", 5)\n",
        "            )\n",
        "\n",
        "    # --- Debugging Helper ---\n",
        "    def _print_debug(self, header: str, data: Any):\n",
        "        if self.debug:\n",
        "            print(\"\\n\" + \"=\"*20)\n",
        "            print(f\"DEBUG: {header}\")\n",
        "            print(\"=\"*20)\n",
        "            pprint(data)\n",
        "        return data # Pass data through unchanged\n",
        "\n",
        "    def _tap_and_log(self, x: dict) -> dict:\n",
        "        \"\"\"\n",
        "        A helper method to print debug info and pass the input dictionary through unchanged.\n",
        "        \"\"\"\n",
        "        self._print_debug(\"Final Context for LLM\", x.get(\"context_str\", \"Context not available\"))\n",
        "        return x\n",
        "\n",
        "    def _get_unique_union(self, documents: list[list]) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Takes a list of document lists, merges them, and removes duplicates.\n",
        "        \"\"\"\n",
        "        # Serialize each document to a string to make them hashable\n",
        "        flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "        # Use a set to get unique serialized documents\n",
        "        unique_docs = list(set(flattened_docs))\n",
        "        # Deserialize unique documents back into Document objects\n",
        "        return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "    # --- Retrieval Strategy Helpers ---\n",
        "\n",
        "    def _get_multi_query_chain(self):\n",
        "        # Builds a chain that generates multiple queries and retrieves documents for each.\n",
        "        # 1. Prompt for generating multiple queries\n",
        "        template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "        different versions of the given user question to retrieve relevant documents from a vector\n",
        "        database. By generating multiple perspectives on the user question, your goal is to help\n",
        "        the user overcome some of the limitations of the cosine-based similarity search.\n",
        "        Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "        prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        # 3. The chain for generating and retrieving\n",
        "        generate_queries = (\n",
        "            prompt_perspectives\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Queries\", x))\n",
        "        )\n",
        "\n",
        "        retrieval_chain = generate_queries | self.retriever.map() | self._get_unique_union | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_rag_fusion_chain(self):\n",
        "        \"\"\"Builds a chain for RAG Fusion with reciprocal rank fusion.\"\"\"\n",
        "        # 1. The multi-query generation is the same as above\n",
        "        template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "        different versions of the given user question to retrieve relevant documents from a vector\n",
        "        database. By generating multiple perspectives on the user question, your goal is to help\n",
        "        the user overcome some of the limitations of the cosine-based similarity search.\n",
        "        Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "        prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "        generate_queries = (\n",
        "            prompt_perspectives\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Queries\", x))\n",
        "        )\n",
        "\n",
        "        # 2. Reranking with Reciprocal Rank Fusion\n",
        "        def reciprocal_rank_fusion(results: list[list], k=60):\n",
        "            fused_scores = {}\n",
        "            for docs in results:\n",
        "                for rank, doc in enumerate(docs):\n",
        "                    doc_str = dumps(doc)\n",
        "                    if doc_str not in fused_scores:\n",
        "                        fused_scores[doc_str] = 0\n",
        "                    fused_scores[doc_str] += 1 / (rank + k)\n",
        "\n",
        "            # .item() converts [doc_str: score] pairs to a list of tuples [doc_str, score]\n",
        "            # Sort by score in descending order (reverse=True)\n",
        "            reranked_results = [\n",
        "                (loads(doc), score)\n",
        "                for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            ]\n",
        "            self._print_debug(\"Reranked Documents (RAG Fusion)\", reranked_results)\n",
        "            # Return only the documents, not the scores\n",
        "            return [doc for doc, score in reranked_results]\n",
        "\n",
        "        # 3. The RAG Fusion chain\n",
        "        retrieval_chain = generate_queries | self.retriever.map() | reciprocal_rank_fusion\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_decomposition_chain(self):\n",
        "        # Builds a chain that decomposes a question into sub-questions.\n",
        "        # 1. Prompt for generating sub-questions\n",
        "        decomposition_template = \"\"\"You are a helpful assistant that generates multiple sub-questions\n",
        "        related to an input question. The goal is to break down the input into a set of sub-problems\n",
        "        that can be answered in isolation. Generate multiple search queries related to: {question}\n",
        "        Output (separated by newlines):\"\"\"\n",
        "        prompt_decomposition = ChatPromptTemplate.from_template(decomposition_template)\n",
        "\n",
        "        # 2. Chain to generate and clean up sub-questions\n",
        "        generate_queries_decomposition = (\n",
        "            prompt_decomposition\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | (lambda x: x.split(\"\\n\"))\n",
        "            | RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Decomposed Sub-questions\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain using the decomposed questions\n",
        "        retrieval_chain = (\n",
        "            generate_queries_decomposition\n",
        "            | self.retriever.map()\n",
        "            | self._get_unique_union\n",
        "            | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (Decomposition)\", docs)\n",
        "            ))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_step_back_chain(self):\n",
        "        # Builds a chain that generates a general, \"stepped-back\" question and retrieves documents for it.\n",
        "        # 1. Prompt to generate a more general, \"stepped-back\" question\n",
        "        step_back_template = \"\"\"You are an expert at world knowledge. Your task is to step back and\n",
        "        paraphrase a question to a more generic step-back question, which is easier to answer.\n",
        "\n",
        "        Here are a few examples:\n",
        "        Original Question: What is the C29x CPU architecture in the F29H85x microcontroller?\n",
        "        Step-Back Question: What are the technical specifications of the C29x CPU architecture?\n",
        "\n",
        "        Original Question: Which TI device was recommended for automotive radar in the 2023 safety seminar?\n",
        "        Step-Back Question: What are some common TI devices used for automotive radar applications?\n",
        "\n",
        "        Original Question: {question}\n",
        "        Step-Back Question:\"\"\"\n",
        "        prompt_step_back = ChatPromptTemplate.from_template(step_back_template)\n",
        "\n",
        "        # 2. Chain to generate the new question\n",
        "        generate_step_back_query = (\n",
        "            prompt_step_back\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            #| (lambda x: x.split(\"\\n\"))\n",
        "            #| RunnableLambda(lambda x: [q for q in x if q.strip()])\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Step-Back Question\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain using the new question\n",
        "        # This takes the original question, generates a new one, and retrieves docs with it\n",
        "        retrieval_chain = generate_step_back_query | self.retriever | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (Step back)\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def _get_hyde_chain(self):\n",
        "        # Builds a chain that generates a hypothetical document and uses it for retrieval.\n",
        "\n",
        "        # 1. Prompt to generate a hypothetical document (a plausible answer)\n",
        "        hyde_template = \"\"\"Please write a passage to answer the user's question.\n",
        "        This passage should be detailed and informative, as if it came from a technical document.\n",
        "        The purpose is to create a rich text for a vector search.\n",
        "\n",
        "        Question: {question}\n",
        "        Passage:\"\"\"\n",
        "        prompt_hyde = ChatPromptTemplate.from_template(hyde_template)\n",
        "\n",
        "        # 2. Chain to generate the hypothetical document\n",
        "        generate_hyde_document = (\n",
        "            prompt_hyde\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "            | RunnableLambda(lambda x: self._print_debug(\"Generated Hypothetical Document\", x))\n",
        "        )\n",
        "\n",
        "        # 3. The full retrieval chain: generate a hypothetical doc, then retrieve with it\n",
        "        retrieval_chain = generate_hyde_document | self.retriever | RunnableLambda(lambda docs: self._print_debug(\"Retrieved Documents (HyDE)\", docs))\n",
        "        return retrieval_chain\n",
        "\n",
        "    def invoke(self, question: str) -> dict:\n",
        "        \"\"\"\n",
        "        Builds and invokes the RAG chain based on the configuration.\n",
        "\n",
        "        Args:\n",
        "            question (str): The user's question.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the question, retrieved context, and the final answer.\n",
        "        \"\"\"\n",
        "        strategy = self.config.get(\"retrieval_strategy\", \"simple\")\n",
        "\n",
        "        # LLM_only strategy does not use retrieval\n",
        "        if strategy == \"llm_only\":\n",
        "            self._print_debug(\"Strategy\", \"LLM Only (No RAG)\")\n",
        "            answer = self.llm.invoke(question).content\n",
        "            return {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"strategy\": strategy,\n",
        "                \"context\": \"N/A\" # No context was used\n",
        "            }\n",
        "\n",
        "         # --- For RAG-based strategies ---\n",
        "        if strategy == \"multi_query\":\n",
        "            retrieval_chain = self._get_multi_query_chain()\n",
        "        elif strategy == \"rag_fusion\":\n",
        "            retrieval_chain = self._get_rag_fusion_chain()\n",
        "        elif strategy == \"decomposition\":\n",
        "            retrieval_chain = self._get_decomposition_chain()\n",
        "        elif strategy == \"step_back\":\n",
        "            retrieval_chain = self._get_step_back_chain()\n",
        "        elif strategy == \"hyde\":\n",
        "            retrieval_chain = self._get_hyde_chain()\n",
        "        # -----------------------------\n",
        "        else: # Default to simple retrieval\n",
        "            retrieval_chain = self.retriever | RunnableLambda(\n",
        "                lambda docs: self._print_debug(\"Retrieved Documents (Simple)\", docs)\n",
        "            )\n",
        "\n",
        "        final_prompt_template = \"\"\"Answer the following question based only on the provided context...\n",
        "        <context>{context}</context>\n",
        "        Question: {question}\"\"\"\n",
        "        final_prompt = ChatPromptTemplate.from_template(final_prompt_template)\n",
        "\n",
        "        def format_docs(docs: List[Document]) -> str:\n",
        "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "        # Define the main RAG processing steps\n",
        "        rag_steps = (\n",
        "            RunnablePassthrough.assign(\n",
        "                context_str=itemgetter(\"context\") | RunnableLambda(format_docs)\n",
        "            )\n",
        "            #| RunnableLambda(self._tap_and_log)\n",
        "        )\n",
        "\n",
        "        # Define the final chain that uses the processed steps\n",
        "        rag_chain = (\n",
        "            {\"context\": retrieval_chain, \"question\": RunnablePassthrough()}\n",
        "            | rag_steps\n",
        "            | {\n",
        "                  \"answer\": (\n",
        "                      lambda x: {\"context\": x[\"context_str\"], \"question\": x[\"question\"]}\n",
        "                  ) | final_prompt | self.llm | StrOutputParser(),\n",
        "                  \"context\": itemgetter(\"context\"),\n",
        "              }\n",
        "        )\n",
        "\n",
        "        result = rag_chain.invoke(question)\n",
        "\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer\": result['answer'],\n",
        "            \"strategy\": strategy,\n",
        "            \"context\": result['context']\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4CRI_GB-btq",
        "outputId": "ee0ac2f7-0316-4a41-fdf4-728b32c3fb8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Running with RAG Fusion Strategy (Debug Mode) ---\n",
            "\n",
            "====================\n",
            "DEBUG: Generated Hypothetical Document\n",
            "====================\n",
            "('The document focuses on the latest advancements and specifications of the '\n",
            " 'AWR2843 mmWave Integrated Circuit (IC), a highly versatile and efficient '\n",
            " 'device designed for a wide range of applications in automotive radar, '\n",
            " 'industrial automation, and smart infrastructure systems. The AWR2843 is part '\n",
            " \"of Texas Instruments' 77 GHz to 81 GHz mmWave sensor family, incorporating \"\n",
            " 'advanced features that enable superior performance in environmental sensing '\n",
            " 'and high-resolution imaging.\\n'\n",
            " '\\n'\n",
            " 'Key features of the AWR2843 include integrated transmit and receive (Tx/Rx) '\n",
            " 'capabilities, facilitating robust radar functionalities with up to four '\n",
            " 'transmitters and four receivers. This architecture supports a variety of '\n",
            " 'radar configurations, offering spatial resolution and accurate distance '\n",
            " 'measurement essential for sophisticated applications such as adaptive cruise '\n",
            " 'control and pedestrian detection. The IC operates within a wide temperature '\n",
            " 'range from -40°C to +105°C, ensuring reliability in diverse environmental '\n",
            " 'conditions.\\n'\n",
            " '\\n'\n",
            " 'The AWR2843 further exemplifies its versatility through its integrated '\n",
            " 'digital signal processing capabilities. Utilizing a powerful onboard '\n",
            " 'processor, it can perform complex signal analysis and data extraction in '\n",
            " 'real time. The device supports advanced algorithms for object detection, '\n",
            " 'ranging, and velocity estimation, accommodating enhanced functionalities in '\n",
            " 'autonomous vehicle systems and industrial automation environments.\\n'\n",
            " '\\n'\n",
            " 'In terms of packaging, the AWR2843 comes in a compact QFN (Quad Flat '\n",
            " 'No-lead) format, optimizing thermal performance and minimizing parasitic '\n",
            " 'inductances, which are critical for high-frequency operation. The device '\n",
            " 'also features flexible power management options, making it suitable for '\n",
            " 'battery-powered applications and facilitating energy-efficient designs.\\n'\n",
            " '\\n'\n",
            " 'For seamless integration into existing systems, the AWR2843 is compatible '\n",
            " 'with a wide range of development tools and evaluation platforms offered by '\n",
            " 'Texas Instruments. Designers can leverage extensive software development '\n",
            " 'kits (SDKs) along with reference designs to expedite time-to-market and '\n",
            " 'simplify the design process.\\n'\n",
            " '\\n'\n",
            " 'In summary, the AWR2843 mmWave IC represents a significant step forward in '\n",
            " 'radar technology, empowering engineers and developers to innovate and '\n",
            " 'optimize their designs across numerous sectors, from automotive safety to '\n",
            " 'smart city infrastructures. Its combination of advanced features, integrated '\n",
            " 'processing capabilities, and versatile packaging makes the AWR2843 an ideal '\n",
            " 'choice for emerging mmWave applications.')\n",
            "\n",
            "====================\n",
            "DEBUG: Retrieved Documents (HyDE)\n",
            "====================\n",
            "[Document(metadata={'id': 'pdf_doc_1_chunk_10_cd57b3cc0f1d4d0aad61dc9205171ec3'}, page_content='radar signal processing can be done within the Radar Hardware Accelerator, while still retaining the\\nflexibility of implementing other proprietary algorithms in the main processor.\\n1.2 Key Features\\nThe main features of the Radar Hardware Accelerator are as follows.\\n• Fast FFT computation, with programmable FFT sizes (powers of 2) up to 1024-pt complex FFT\\n• Internal FFT bit width of 24 bits (for each I and Q) for good SQNR performance, with fully\\nprogrammable butterfly scaling at every radix-2 stage for user flexibility\\n• Built-in capabilities for simple pre-FFT processing – specifically, programmable windowing, basic\\ninterference zeroing-out, and basic BPM removal\\n• Magnitude (absolute value) and log-magnitude computation capability\\n• Flexible data flow and data sample arrangement to support efficient multidimensional FFT operations\\nand transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_11_c8d7d5fdc9e841ef86a0c5251616e94c'}, page_content=\"and transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with\\nminimal intervention from the main processor\\n• CFAR-CA detector support (linear and logarithmic)\\n• Miscellaneous other capabilities of the accelerator:\\n– Stitching two or four 1024-point FFTs to get the equivalent of 2048-point or 4096-point FFT for\\nindustrial level sensing applications where large FFT sizes are required\\n– Slow DFT mode, with resolution equivalent to 16K size FFT, for FFT peak interpolation purposes\\n(for example, range interpolation)\\n– Complex vector multiplication and Dot product capability for vectors up to 512 in size\\nThis user's guide is divided into two parts. The first part covers the high-level architecture and key features\\nsuch as windowing, FFT, and log-magnitude. The (optional) second part covers additional features such\\nas CFAR-CA, complex multiplication, and so forth.128\\n-bit bus\\nDMA\\nRADAR HW ACCELERATOR \\nCortex R4F\"),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_135_386a3ebf66f34514acfe40554839a9fc'}, page_content=\"6.1 Ultra-Short-Range Radar Use Case\\nThis example illustrates a typical end-to-end radar signal processing flow and how it can be accomplished\\nusing the Radar Hardware Accelerator and Cortex-R4F processor. The use case assumes a two-TX, two-\\nRX configuration, with a chirp profile as in Table 6.\\nTable 6. Chirp Configuration Used for Illustration\\nParameter Value Comments\\nChirp duration 50 µs (active) + 10\\nµs (idle)\\n–\\nSweep bandwidth 2 GHz 7.5-cm range resolution\\nRamp slope 40 MHz/µs –\\nMaximum range 15 m –\\nMaximum beat frequency 4 MHz –\\nADC sampling rate 4.5 MHz Complex I,Q sampling\\nNumber of samples per chirp 225 –\\nFirst-dimension FFT size 256 225 samples + 31 zeros\\nNumber of chirps per frame 64 × 2 = 128 TX1, TX2 alternating (64 chirps each)\\nNumber of channels Two TX, two RX Effective four channels (assuming sparse antenna array with TX's ʎ-separated\\nand RX’s ʎ / 2-separated)\\nRadar cube data memory 256 KB 256 × (64 × 2) × 2 × 2 × 2 = 262144 bytes\\nFrame time 128 × 60 µs = 7.68\\nms\\n–\"),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_62_c698d2044062482c86a5b1702962c84b'}, page_content='throughput of one complex sample per clock cycle. The input formatter thus feeds one sample (24-bit I\\nand 24-bit Q) into the core computational unit every clock cycle.\\nTo make the best use of the capabilities of the core computational unit and to allow meaningful chaining of\\nradar signal processing operations with minimal intervention from the R4F processor, the input formatter\\nsupports flexibility in how the input samples are accessed from the memory and how they are formatted\\nand fed into the core computational unit.Accelerator Engine – Input Formatter www.ti.com\\n16 SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\nThe memory from which the input formatter picks up the data is referred to as source memory. Note that\\nany of the four accelerator local memories can be the source memory. However, as will be described in a'),\n",
            " Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='the DMA and written back into the Radar data memory for further processing by the main processor.\\nNote that in the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single\\nchip along with the mmWave RF and analog front end. In this device, two of the accelerator local\\nmemories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC\\nbuffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are\\ndirectly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without\\nneeding a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the\\nactive transmission of chirps in a frame), it is possible to freely use these memories for second-dimension\\nFFT processing by bringing in data to these memories through DMA transfer.\\nThe purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator')]\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "{'answer': 'The document is about the mmWave 14xx device.',\n",
            " 'context': [Document(metadata={'id': 'pdf_doc_1_chunk_10_cd57b3cc0f1d4d0aad61dc9205171ec3'}, page_content='radar signal processing can be done within the Radar Hardware Accelerator, while still retaining the\\nflexibility of implementing other proprietary algorithms in the main processor.\\n1.2 Key Features\\nThe main features of the Radar Hardware Accelerator are as follows.\\n• Fast FFT computation, with programmable FFT sizes (powers of 2) up to 1024-pt complex FFT\\n• Internal FFT bit width of 24 bits (for each I and Q) for good SQNR performance, with fully\\nprogrammable butterfly scaling at every radix-2 stage for user flexibility\\n• Built-in capabilities for simple pre-FFT processing – specifically, programmable windowing, basic\\ninterference zeroing-out, and basic BPM removal\\n• Magnitude (absolute value) and log-magnitude computation capability\\n• Flexible data flow and data sample arrangement to support efficient multidimensional FFT operations\\nand transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_11_c8d7d5fdc9e841ef86a0c5251616e94c'}, page_content=\"and transpose accesses as required\\n• Chaining and looping mechanism to sequence a set of accelerator operations one-after-another with\\nminimal intervention from the main processor\\n• CFAR-CA detector support (linear and logarithmic)\\n• Miscellaneous other capabilities of the accelerator:\\n– Stitching two or four 1024-point FFTs to get the equivalent of 2048-point or 4096-point FFT for\\nindustrial level sensing applications where large FFT sizes are required\\n– Slow DFT mode, with resolution equivalent to 16K size FFT, for FFT peak interpolation purposes\\n(for example, range interpolation)\\n– Complex vector multiplication and Dot product capability for vectors up to 512 in size\\nThis user's guide is divided into two parts. The first part covers the high-level architecture and key features\\nsuch as windowing, FFT, and log-magnitude. The (optional) second part covers additional features such\\nas CFAR-CA, complex multiplication, and so forth.128\\n-bit bus\\nDMA\\nRADAR HW ACCELERATOR \\nCortex R4F\"),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_135_386a3ebf66f34514acfe40554839a9fc'}, page_content=\"6.1 Ultra-Short-Range Radar Use Case\\nThis example illustrates a typical end-to-end radar signal processing flow and how it can be accomplished\\nusing the Radar Hardware Accelerator and Cortex-R4F processor. The use case assumes a two-TX, two-\\nRX configuration, with a chirp profile as in Table 6.\\nTable 6. Chirp Configuration Used for Illustration\\nParameter Value Comments\\nChirp duration 50 µs (active) + 10\\nµs (idle)\\n–\\nSweep bandwidth 2 GHz 7.5-cm range resolution\\nRamp slope 40 MHz/µs –\\nMaximum range 15 m –\\nMaximum beat frequency 4 MHz –\\nADC sampling rate 4.5 MHz Complex I,Q sampling\\nNumber of samples per chirp 225 –\\nFirst-dimension FFT size 256 225 samples + 31 zeros\\nNumber of chirps per frame 64 × 2 = 128 TX1, TX2 alternating (64 chirps each)\\nNumber of channels Two TX, two RX Effective four channels (assuming sparse antenna array with TX's ʎ-separated\\nand RX’s ʎ / 2-separated)\\nRadar cube data memory 256 KB 256 × (64 × 2) × 2 × 2 × 2 = 262144 bytes\\nFrame time 128 × 60 µs = 7.68\\nms\\n–\"),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_62_c698d2044062482c86a5b1702962c84b'}, page_content='throughput of one complex sample per clock cycle. The input formatter thus feeds one sample (24-bit I\\nand 24-bit Q) into the core computational unit every clock cycle.\\nTo make the best use of the capabilities of the core computational unit and to allow meaningful chaining of\\nradar signal processing operations with minimal intervention from the R4F processor, the input formatter\\nsupports flexibility in how the input samples are accessed from the memory and how they are formatted\\nand fed into the core computational unit.Accelerator Engine – Input Formatter www.ti.com\\n16 SWRU526– May 2017\\nSubmit Documentation Feedback\\nCopyright © 2017, Texas Instruments Incorporated\\nRadar Hardware Accelerator - Part 1\\nThe memory from which the input formatter picks up the data is referred to as source memory. Note that\\nany of the four accelerator local memories can be the source memory. However, as will be described in a'),\n",
            "             Document(metadata={'id': 'pdf_doc_1_chunk_15_9280380379c945fdbfce32b0fe5183f1'}, page_content='the DMA and written back into the Radar data memory for further processing by the main processor.\\nNote that in the mmWave 14xx device, the Radar Hardware Accelerator is included as part of a single\\nchip along with the mmWave RF and analog front end. In this device, two of the accelerator local\\nmemories, namely ACCEL_MEM0 and ACCEL_MEM1, are directly shared with the ping and pong ADC\\nbuffers (which are 16KB each) – such that the ADC output samples for first-dimension FFT processing are\\ndirectly and immediately available to the Radar Hardware Accelerator at the end of each chirp, without\\nneeding a DMA transfer. After the first-dimension FFT processing is complete (typically, at the end of the\\nactive transmission of chirps in a frame), it is possible to freely use these memories for second-dimension\\nFFT processing by bringing in data to these memories through DMA transfer.\\nThe purpose behind the four separate local memories (16KB each) inside the Radar Hardware Accelerator')],\n",
            " 'question': 'Which mmwave IC is the document about?',\n",
            " 'strategy': 'hyde'}\n",
            "\n",
            "\n",
            "--- Running with LLM Only Strategy ---\n",
            "\n",
            "--- FINAL OUTPUT ---\n",
            "{'answer': \"I'm sorry, but I don't have access to external documents or \"\n",
            "           'specific content that you may be referring to. However, if you '\n",
            "           'provide me with details or context from the document, I may be '\n",
            "           'able to help answer your questions or provide information related '\n",
            "           'to mmWave ICs.',\n",
            " 'context': 'N/A',\n",
            " 'question': 'Which mmwave IC is the document about?',\n",
            " 'strategy': 'llm_only'}\n"
          ]
        }
      ],
      "source": [
        "# --- Example Usage ---\n",
        "# main.py\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "# Get API keys using using dotenv\n",
        "load_dotenv()\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY_SHIVAM\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Get API keys using google.colab\n",
        "# from google.colab import userdata\n",
        "# OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "# PINECONE_API_KEY = userdata.get('PINECONE_API_KEY_SHIVAM')\n",
        "\n",
        "\n",
        "# --- Example 1: RAG Fusion with Debugging Enabled ---\n",
        "print(\"--- Running with RAG Fusion Strategy (Debug Mode) ---\")\n",
        "fusion_config = {\n",
        "    \"llm_model\": \"gpt-4o-mini\",\n",
        "    \"retrieval_strategy\": \"hyde\",\n",
        "    \"index_name\": \"swru526-pine\",\n",
        "    \"namespace\": \"example-namespace\",\n",
        "    \"top_k\": 5,\n",
        "    \"debug\": True  # <-- Enable debugging\n",
        "}\n",
        "\n",
        "orchestrator_fusion = RAGOrchestrator(fusion_config)\n",
        "question = \"Which mmwave IC is the document about?\"\n",
        "result_fusion = orchestrator_fusion.invoke(question)\n",
        "print(\"\\n--- FINAL OUTPUT ---\")\n",
        "pprint(result_fusion)\n",
        "\n",
        "\n",
        "# --- Example 2: LLM Only (No RAG) via Config ---\n",
        "print(\"\\n\\n\" + \"--- Running with LLM Only Strategy ---\")\n",
        "llm_only_config = {\n",
        "    \"llm_model\": \"gpt-4o-mini\",\n",
        "    \"retrieval_strategy\": \"llm_only\",\n",
        "    \"debug\": False # Debug flag works here too\n",
        "}\n",
        "\n",
        "orchestrator_llm_only = RAGOrchestrator(llm_only_config)\n",
        "result_llm_only = orchestrator_llm_only.invoke(question)\n",
        "print(\"\\n--- FINAL OUTPUT ---\")\n",
        "pprint(result_llm_only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXmKoJU9jJqj"
      },
      "outputs": [],
      "source": [
        "# 1. Core Retrieval Strategy\n",
        "# This is the main method used to find and fetch the initial set of documents.\n",
        "#     \"simple\": A single vector search against the user's query.\n",
        "#     \"multi_query\": Generates multiple variations of the query and combines the results (unique union).\n",
        "#     \"rag_fusion\": Generates multiple variations of the query and combines the results using Reciprocal Rank Fusion.\n",
        "#     \"decomposition\": Breaks a complex query into sub-questions and retrieves for each.\n",
        "#     \"step_back\": Asks a more general question to get broader context.\n",
        "#     \"hyde\": Generates a hypothetical document to guide the search.\n",
        "#     \"llm_only\": No retrieval at all.\n",
        "\n",
        "# 2. Post-Retrieval Processing\n",
        "# This defines what happens to the documents after they are retrieved but before they are sent to the LLM.\n",
        "#     \"none\": No processing; use the documents as-is.\n",
        "#     \"semantic_re_ranking\": Use a more powerful Cross-Encoder to re-rank the documents for semantic relevance.\n",
        "\n",
        "# 3. Final Prompting Strategy\n",
        "# This determines how the LLM is instructed to use the context to formulate the final answer.\n",
        "#     \"strict_context\": The prompt will strictly forbid the LLM from using any knowledge outside of the provided documents.\n",
        "#     \"permissive_context\": The prompt will encourage the LLM to primarily use the context but allow it to synthesize an answer using its general knowledge if needed.\n",
        "\n",
        "# 4. General Parameters\n",
        "# These are the basic \"knobs\" for any given run.\n",
        "#     \"llm_model\": e.g., \"gpt-4o-mini\", \"gpt-4o\"\n",
        "#     \"index_name\": The specific Pinecone index to target.\n",
        "#     \"namespace\": The namespace within that index.\n",
        "#     \"top_k\": The number of documents to retrieve initially.\n",
        "#     \"debug\": True or False."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
